{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buucK6eBXbL4"
      },
      "outputs": [],
      "source": [
        "# drive mount. colab에 내 구글 드라이브 연결\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "import transformers\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification\n",
        "import torch\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "T9BiIilFXzVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU 찾기. 없으면 CPU로 동작\n",
        "if torch.cuda.is_available():  \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "# check torch is available\n",
        "print(torch.__version__)\n",
        "print(torch.tensor([1.0, 2.0]).cuda())"
      ],
      "metadata": {
        "id": "WFpJ3ZDCP9wS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_subtokens(tokens, relevance_score):\n",
        "    '''\n",
        "    combine subtokens to one word\n",
        "    '''\n",
        "\n",
        "    token = ['[CLS]', '[SEP]', '[MASK]', '[UNK]', '[PAD]']\n",
        "\n",
        "    word, score, num = [], [], []\n",
        "\n",
        "    for i in range(len(tokens)):\n",
        "      if tokens[i] in token: continue\n",
        "      if tokens[i][0]=='#':\n",
        "        word[-1]+=tokens[i][2:]\n",
        "        score[-1]+=relevance_score[i]\n",
        "        num[-1]+=1\n",
        "      else:\n",
        "        word.append(tokens[i])\n",
        "        score.append(relevance_score[i])\n",
        "        num.append(1)\n",
        "    \n",
        "    for i in range(len(word)): score[i]/=num[i]\n",
        "    \n",
        "    return word, score\n"
      ],
      "metadata": {
        "id": "1fuv0fuEXnpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_output(string,tokenizer,model):  \n",
        "  encoded_dict = tokenizer.encode_plus(\n",
        "                      string, \n",
        "                      add_special_tokens = True,\n",
        "                      max_length = 512,\n",
        "                      truncation=True,\n",
        "                      pad_to_max_length = True,\n",
        "                      return_attention_mask = True,\n",
        "                      return_tensors = 'pt',\n",
        "                )\n",
        "  input_ids = encoded_dict['input_ids'].to(device)\n",
        "  attention_masks = encoded_dict['attention_mask'].to(device)\n",
        "  output = torch.nn.functional.softmax(model(input_ids=input_ids, attention_mask=attention_masks)[0], dim=-1).detach().cpu().numpy()\n",
        "  return output\n",
        "\n",
        "\n",
        "def get_comp_suff(tokens, expl, tokenizer, model, rationale_num):\n",
        "  tokens_comb, expl_comb = combine_subtokens(tokens, list(expl))\n",
        "\n",
        "  top_score = [(expl_comb[i],i) for i in range(len(expl_comb))]\n",
        "  top_score.sort(reverse=True)\n",
        "  top_score_idx = set(i for _,i in top_score[:rationale_num])\n",
        "\n",
        "  no_rationale_tokens = []\n",
        "  rationale_tokens = []\n",
        "  for i, token in enumerate(tokens_comb):\n",
        "    if i in top_score_idx: rationale_tokens.append(token)\n",
        "    else: no_rationale_tokens.append(token)\n",
        "  \n",
        "  orig_string = tokenizer.convert_tokens_to_string(tokens_comb)\n",
        "  no_rationale_string = tokenizer.convert_tokens_to_string(no_rationale_tokens)\n",
        "  rationale_string = tokenizer.convert_tokens_to_string(rationale_tokens)\n",
        "\n",
        "  orig_output = get_output(orig_string,tokenizer,model)[0][1]\n",
        "  no_rationale_output = get_output(no_rationale_string,tokenizer,model)[0][1]\n",
        "  rationale_output = get_output(rationale_string,tokenizer,model)[0][1]\n",
        "  \n",
        "  comp = orig_output-no_rationale_output\n",
        "  suff = orig_output-rationale_output\n",
        "  return comp, suff\n",
        "\n",
        "\n",
        "def get_comp_suff_all(target_model_name, expl_name, rationale_num = 3,data_num = 5):\n",
        "  root = \"/content/drive/MyDrive/CS470_team_2in1/colab\"\n",
        "\n",
        "  records = np.load(root+'/explanation/balanced_only1000model/'+expl_name, allow_pickle=True)\n",
        "\n",
        "  tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "  target_model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "  target_model.load_state_dict(torch.load(root+'/model/'+target_model_name, map_location=device))\n",
        "  target_model.cuda()\n",
        "\n",
        "  total_comp = 0\n",
        "  total_suff = 0\n",
        "  num = 0\n",
        "  for tokens, rating, product, output, neg_expl, pos_expl, true_class, pred_class in records:\n",
        "    if num==data_num: break\n",
        "    if not(len(tokens)==len(neg_expl)==len(pos_expl)): continue\n",
        "    if len(combine_subtokens(tokens, list(pos_expl))[0])<rationale_num*2: continue\n",
        "\n",
        "    comp, suff = get_comp_suff(tokens,pos_expl,tokenizer,target_model,rationale_num)\n",
        "    total_comp+=comp\n",
        "    total_suff+=suff\n",
        "\n",
        "    num+=1\n",
        "  \n",
        "  total_comp/=data_num\n",
        "  total_suff/=data_num\n",
        "\n",
        "  return total_comp,total_suff"
      ],
      "metadata": {
        "id": "iXZjnl_S2s8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comp,suff = get_comp_suff_all(target_model_name='amazon_book_only1000_binaryclassification_testacc097.pt', expl_name='amazon_book_expl-transformer_attribution-binaryclassification_only10000.npy', rationale_num = 5,data_num = 100)\n",
        "print(comp,suff)"
      ],
      "metadata": {
        "id": "dl03rAZtQjxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comp,suff = get_comp_suff_all(target_model_name='amazon_book_only1000_binaryclassification_testacc097.pt', expl_name='amazon_book_expl-transformer_attribution-binaryclassification_notrained_only10000.npy', rationale_num = 5,data_num = 100)\n",
        "print(comp,suff)"
      ],
      "metadata": {
        "id": "7Qlms8pET_6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comp,suff = get_comp_suff_all(target_model_name='amazon_book_only1000_binaryclassification_testacc097.pt', expl_name='amazon_book_expl-transformer_attribution-regression_only10000.npy', rationale_num = 5,data_num = 100)\n",
        "print(comp,suff)"
      ],
      "metadata": {
        "id": "wZW_PjULVlJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comp,suff = get_comp_suff_all(target_model_name='amazon_book_only1000_binaryclassification_testacc097.pt', expl_name='amazon_book_expl-partial_lrp-regression_only10000.npy', rationale_num = 5,data_num = 100)\n",
        "print(comp,suff)"
      ],
      "metadata": {
        "id": "2HPvKkhCRhhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "comp_list, suff_list = [], []\n",
        "binary_expl_npy = 'amazon_book_expl-transformer_attribution-binaryclassification_only10000.npy'\n",
        "regression_expl_npy = 'amazon_book_expl-transformer_attribution-regression_only10000.npy'\n",
        "for rat_num in tqdm(range(1, 100, 2)):\n",
        "    comp,suff = get_comp_suff_all(target_model_name='amazon_book_only1000_binaryclassification_testacc097.pt', expl_name=binary_expl_npy, rationale_num = rat_num,data_num = 100)\n",
        "    # print(comp,suff)\n",
        "    comp_list.append(comp)\n",
        "    suff_list.append(suff)\n"
      ],
      "metadata": {
        "id": "QcX2QqQgRiKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_comp_list, reg_suff_list = [], []\n",
        "binary_expl_npy = 'amazon_book_expl-transformer_attribution-binaryclassification_only10000.npy'\n",
        "regression_expl_npy = 'amazon_book_expl-transformer_attribution-regression_only10000.npy'\n",
        "for rat_num in tqdm(range(1, 100, 2)):\n",
        "    comp,suff = get_comp_suff_all(target_model_name='amazon_book_only1000_binaryclassification_testacc097.pt', expl_name=regression_expl_npy, rationale_num = rat_num,data_num = 100)\n",
        "    # print(comp,suff)\n",
        "    reg_comp_list.append(comp)\n",
        "    reg_suff_list.append(suff)"
      ],
      "metadata": {
        "id": "UX8S1FuSbtpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "not_comp_list, not_suff_list = [], []\n",
        "binary_expl_npy = 'amazon_book_expl-transformer_attribution-binaryclassification_only10000.npy'\n",
        "regression_expl_npy = 'amazon_book_expl-transformer_attribution-regression_only10000.npy'\n",
        "notrained_expl_npy = 'amazon_book_expl-transformer_attribution-binaryclassification_notrained_only10000.npy'\n",
        "for rat_num in tqdm(range(1, 100, 2)):\n",
        "    comp,suff = get_comp_suff_all(target_model_name='amazon_book_only1000_binaryclassification_testacc097.pt', expl_name=notrained_expl_npy, rationale_num = rat_num,data_num = 100)\n",
        "    # print(comp,suff)\n",
        "    not_comp_list.append(comp)\n",
        "    not_suff_list.append(suff)"
      ],
      "metadata": {
        "id": "uFs1aE94ftFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot([2*i+1 for i in range(len(comp_list))], comp_list, label='binary')\n",
        "plt.plot([2*i+1 for i in range(len(reg_comp_list))], reg_comp_list, label='regression')\n",
        "plt.plot([2*i+1 for i in range(len(not_comp_list))], not_comp_list, label='not trained')\n",
        "plt.title('comprehensiveness')\n",
        "plt.xlabel('# of rationales')\n",
        "plt.legend(('binary', 'regression', 'not trained'))\n",
        "# plt.ylabel('comprehensiveness')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot([2*i+1 for i in range(len(suff_list))], suff_list, label='sufficiency')\n",
        "plt.plot([2*i+1 for i in range(len(reg_suff_list))], reg_suff_list, label='regression')\n",
        "plt.plot([2*i+1 for i in range(len(not_suff_list))], not_suff_list, label='not trained')\n",
        "plt.title('sufficiency')\n",
        "plt.xlabel('# of rationales')\n",
        "plt.legend(('binary', 'regression', 'not trained')\n",
        "# plt.ylabel('sufficiency')\n",
        "# plt.legend(('train', 'val'))\n",
        "plt.savefig(f'comp_suff_1.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v4j2ETDqVMbC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}